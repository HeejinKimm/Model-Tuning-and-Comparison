{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypFhD7iImcGL",
        "outputId": "64187546-b1ea-493a-d29a-036c5a7e0c30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy9tIhR0eS24",
        "outputId": "87126f9b-ef9f-4691-c03c-8dc0a7d0e61d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/MyDrive/패턴인식/train_processed.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/패턴인식/test_processed.csv')\n",
        "\n",
        "# Feature, Label 나누기 ('shares', 'id' 제거)\n",
        "X = train.drop(['id', 'y', 'shares'], axis=1)\n",
        "y = train['y']\n",
        "\n",
        "# Train/Validation 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# XGBoost 모델 정의 (튜닝된 파라미터)\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=427,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.021978188969319974,\n",
        "    subsample=0.9760848989537714,\n",
        "    colsample_bytree=0.7301003992053027,\n",
        "    gamma=0.2749409209747699,\n",
        "    min_child_weight=1,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# LightGBM 모델 정의\n",
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.02,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# CatBoost 모델 정의 (silent 모드)\n",
        "cb_clf = cb.CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    depth=3,\n",
        "    learning_rate=0.02,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 최종 메타 모델 (Logistic Regression)\n",
        "meta_clf = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
        "\n",
        "# StackingClassifier 정의\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('lgb', lgb_clf),\n",
        "        ('cb', cb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_clf,\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# 검증 예측\n",
        "y_pred_valid = stacking_clf.predict(X_valid)\n",
        "\n",
        "# 평가 결과 출력\n",
        "print(\"Stacking Model Accuracy:\", accuracy_score(y_valid, y_pred_valid))\n",
        "print(\"Stacking Model F1 Score:\", f1_score(y_valid, y_pred_valid))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_valid, y_pred_valid))\n",
        "\n",
        "# 테스트 데이터 예측 후 저장\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "y_pred_test = stacking_clf.predict(X_test)\n",
        "y_prob_test = stacking_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'y_predict': y_pred_test,\n",
        "    'y_prob': y_prob_test\n",
        "})\n",
        "\n",
        "submission.to_csv('prediction_stacking_catboost.csv', index=False)\n",
        "print(\"Done! XGB + LGB + CatBoost Stacking 결과가 prediction_stacking_catboost.csv에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zVCvGSibV4E",
        "outputId": "a12079e7-586a-499f-c49c-2a6b831136b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Model Accuracy: 0.6614864864864864\n",
            "Stacking Model F1 Score: 0.6603389830508475\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.66      0.66      2227\n",
            "           1       0.66      0.66      0.66      2213\n",
            "\n",
            "    accuracy                           0.66      4440\n",
            "   macro avg       0.66      0.66      0.66      4440\n",
            "weighted avg       0.66      0.66      0.66      4440\n",
            "\n",
            "Done! XGB + LGB + CatBoost Stacking 결과가 prediction_stacking_catboost.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/MyDrive/패턴인식/train_processed.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/패턴인식/test_processed.csv')\n",
        "\n",
        "# Feature, Label 나누기 ('shares', 'id' 제거)\n",
        "X = train.drop(['id', 'y', 'shares'], axis=1)\n",
        "y = train['y']\n",
        "\n",
        "# Train/Validation 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 1. XGBoost 모델 정의 (튜닝된 최적 파라미터)\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=427,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.021978188969319974,\n",
        "    subsample=0.9760848989537714,\n",
        "    colsample_bytree=0.7301003992053027,\n",
        "    gamma=0.2749409209747699,\n",
        "    min_child_weight=1,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "xgb_prob = xgb_clf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# 2. Stacking 모델 (XGB + LGB + CB)\n",
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.02,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cb_clf = cb.CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    depth=3,\n",
        "    learning_rate=0.02,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "meta_clf = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('lgb', lgb_clf),\n",
        "        ('cb', cb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_clf,\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "stacking_prob = stacking_clf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# 3. Soft Voting (XGB 0.7 + Stacking 0.3)\n",
        "final_prob = (xgb_prob * 0.7) + (stacking_prob * 0.3)\n",
        "threshold = 0.48\n",
        "final_pred = (final_prob >= threshold).astype(int)\n",
        "\n",
        "# 성능 평가\n",
        "print(\"F1 Score:\", f1_score(y_valid, final_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, final_pred))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_valid, final_pred))\n",
        "\n",
        "# 테스트 예측\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "xgb_test_prob = xgb_clf.predict_proba(X_test)[:, 1]\n",
        "stacking_test_prob = stacking_clf.predict_proba(X_test)[:, 1]\n",
        "final_test_prob = (xgb_test_prob * 0.7) + (stacking_test_prob * 0.3)\n",
        "final_test_pred = (final_test_prob >= threshold).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'y_predict': final_test_pred,\n",
        "    'y_prob': final_test_prob\n",
        "})\n",
        "\n",
        "submission.to_csv('prediction_final_softvote.csv', index=False)\n",
        "print(\"Done! Soft Voting (XGB+Stacking) 결과가 prediction_final_softvote.csv에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnNqSwl2e2NW",
        "outputId": "feea4634-23ef-4307-fd48-6646b3d928cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:54:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.67\n",
            "Accuracy: 0.6581081081081082\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.62      0.65      2227\n",
            "           1       0.65      0.70      0.67      2213\n",
            "\n",
            "    accuracy                           0.66      4440\n",
            "   macro avg       0.66      0.66      0.66      4440\n",
            "weighted avg       0.66      0.66      0.66      4440\n",
            "\n",
            "Done! Soft Voting (XGB+Stacking) 결과가 prediction_final_softvote.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/MyDrive/패턴인식/train_processed.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/패턴인식/test_processed.csv')\n",
        "\n",
        "# Feature, Label 나누기 ('shares', 'id' 제거)\n",
        "X = train.drop(['id', 'y', 'shares'], axis=1)\n",
        "y = train['y']\n",
        "\n",
        "# Train/Validation 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# XGBoost 모델 정의 (튜닝된 최적 파라미터)\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=427,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.021978188969319974,\n",
        "    subsample=0.9760848989537714,\n",
        "    colsample_bytree=0.7301003992053027,\n",
        "    gamma=0.2749409209747699,\n",
        "    min_child_weight=1,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "xgb_prob = xgb_clf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Stacking 모델 정의 (XGB + LGB + CB), meta model: RandomForest\n",
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.02,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cb_clf = cb.CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    depth=3,\n",
        "    learning_rate=0.02,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "meta_clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_clf),\n",
        "        ('lgb', lgb_clf),\n",
        "        ('cb', cb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_clf,\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "stacking_prob = stacking_clf.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Soft Voting 조합\n",
        "final_prob = (xgb_prob * 0.7) + (stacking_prob * 0.3)\n",
        "\n",
        "# F1 Score를 높이기 위한 최적 threshold 탐색\n",
        "best_f1 = 0\n",
        "best_t = 0\n",
        "for t in np.arange(0.40, 0.51, 0.01):\n",
        "    pred = (final_prob >= t).astype(int)\n",
        "    f1 = f1_score(y_valid, pred)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_t = t\n",
        "    print(f\"threshold = {t:.2f} | F1 Score = {f1:.4f} | Accuracy = {accuracy_score(y_valid, pred):.4f}\")\n",
        "\n",
        "print(f\"\\n📌 F1 최적 threshold = {best_t:.2f} (F1 Score = {best_f1:.4f})\")\n",
        "\n",
        "# 최적 threshold로 최종 예측\n",
        "final_pred = (final_prob >= best_t).astype(int)\n",
        "\n",
        "# 성능 평가\n",
        "print(\"\\n최종 F1 기준 평가 결과\")\n",
        "print(\"F1 Score:\", f1_score(y_valid, final_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_valid, final_pred))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_valid, final_pred))\n",
        "\n",
        "# 테스트 예측\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "xgb_test_prob = xgb_clf.predict_proba(X_test)[:, 1]\n",
        "stacking_test_prob = stacking_clf.predict_proba(X_test)[:, 1]\n",
        "final_test_prob = (xgb_test_prob * 0.7) + (stacking_test_prob * 0.3)\n",
        "final_test_pred = (final_test_prob >= best_t).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'y_predict': final_test_pred,\n",
        "    'y_prob': final_test_prob\n",
        "})\n",
        "\n",
        "submission.to_csv('prediction_best_f1.csv', index=False)\n",
        "print(\"\\nDone! F1 최적화 결과가 prediction_best_f1.csv에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlrLyKijiAJN",
        "outputId": "46507506-b83a-4e42-bb72-dbcf7331cb99"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:07:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold = 0.40 | F1 Score = 0.6940 | Accuracy = 0.6354\n",
            "threshold = 0.41 | F1 Score = 0.6889 | Accuracy = 0.6358\n",
            "threshold = 0.42 | F1 Score = 0.6886 | Accuracy = 0.6399\n",
            "threshold = 0.43 | F1 Score = 0.6863 | Accuracy = 0.6432\n",
            "threshold = 0.44 | F1 Score = 0.6860 | Accuracy = 0.6498\n",
            "threshold = 0.45 | F1 Score = 0.6814 | Accuracy = 0.6525\n",
            "threshold = 0.46 | F1 Score = 0.6760 | Accuracy = 0.6523\n",
            "threshold = 0.47 | F1 Score = 0.6712 | Accuracy = 0.6541\n",
            "threshold = 0.48 | F1 Score = 0.6648 | Accuracy = 0.6547\n",
            "threshold = 0.49 | F1 Score = 0.6630 | Accuracy = 0.6592\n",
            "threshold = 0.50 | F1 Score = 0.6603 | Accuracy = 0.6610\n",
            "\n",
            "📌 F1 최적 threshold = 0.40 (F1 Score = 0.6940)\n",
            "\n",
            "최종 F1 기준 평가 결과\n",
            "F1 Score: 0.694008694008694\n",
            "Accuracy: 0.6353603603603604\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.44      0.55      2227\n",
            "           1       0.60      0.83      0.69      2213\n",
            "\n",
            "    accuracy                           0.64      4440\n",
            "   macro avg       0.66      0.64      0.62      4440\n",
            "weighted avg       0.66      0.64      0.62      4440\n",
            "\n",
            "\n",
            "Done! F1 최적화 결과가 prediction_best_f1.csv에 저장되었습니다.\n"
          ]
        }
      ]
    }
  ]
}