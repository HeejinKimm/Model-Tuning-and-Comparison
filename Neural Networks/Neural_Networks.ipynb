{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypFhD7iImcGL",
        "outputId": "ee1fb787-c4c9-4214-fffe-aec0ac941e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zVCvGSibV4E",
        "outputId": "b4efe381-9bd2-4c55-e0af-e41c618552c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5523 - loss: 0.7828 - val_accuracy: 0.6151 - val_loss: 0.6547\n",
            "Epoch 2/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: 0.6640 - val_accuracy: 0.6318 - val_loss: 0.6430\n",
            "Epoch 3/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6443 - loss: 0.6419 - val_accuracy: 0.6403 - val_loss: 0.6364\n",
            "Epoch 4/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 0.6342 - val_accuracy: 0.6446 - val_loss: 0.6341\n",
            "Epoch 5/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 0.6296 - val_accuracy: 0.6405 - val_loss: 0.6333\n",
            "Epoch 6/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6592 - loss: 0.6231 - val_accuracy: 0.6426 - val_loss: 0.6295\n",
            "Epoch 7/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.6140 - val_accuracy: 0.6507 - val_loss: 0.6263\n",
            "Epoch 8/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6586 - loss: 0.6154 - val_accuracy: 0.6475 - val_loss: 0.6279\n",
            "Epoch 9/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6667 - loss: 0.6052 - val_accuracy: 0.6457 - val_loss: 0.6276\n",
            "Epoch 10/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.6023 - val_accuracy: 0.6484 - val_loss: 0.6254\n",
            "Epoch 11/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6656 - loss: 0.6047 - val_accuracy: 0.6514 - val_loss: 0.6248\n",
            "Epoch 12/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.6000 - val_accuracy: 0.6523 - val_loss: 0.6279\n",
            "Epoch 13/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6792 - loss: 0.5956 - val_accuracy: 0.6505 - val_loss: 0.6259\n",
            "Epoch 14/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.5985 - val_accuracy: 0.6495 - val_loss: 0.6253\n",
            "Epoch 15/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6818 - loss: 0.5930 - val_accuracy: 0.6486 - val_loss: 0.6267\n",
            "Epoch 16/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6777 - loss: 0.5934 - val_accuracy: 0.6532 - val_loss: 0.6264\n",
            "Epoch 17/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6831 - loss: 0.5855 - val_accuracy: 0.6518 - val_loss: 0.6248\n",
            "Epoch 18/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6867 - loss: 0.5861 - val_accuracy: 0.6545 - val_loss: 0.6290\n",
            "Epoch 19/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.5870 - val_accuracy: 0.6543 - val_loss: 0.6273\n",
            "Epoch 20/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6903 - loss: 0.5791 - val_accuracy: 0.6547 - val_loss: 0.6301\n",
            "Epoch 21/100\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 0.5785 - val_accuracy: 0.6527 - val_loss: 0.6313\n",
            "\u001b[1m298/298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Done! 결과는 prediction.csv에 저장됐습니다.\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Validation F1 Score: 0.6678\n",
            "Validation AUC Score: 0.7102\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.60      0.63      2227\n",
            "           1       0.64      0.70      0.67      2213\n",
            "\n",
            "    accuracy                           0.65      4440\n",
            "   macro avg       0.65      0.65      0.65      4440\n",
            "weighted avg       0.65      0.65      0.65      4440\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/MyDrive/패턴인식/train_processed.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/패턴인식/test_processed.csv')\n",
        "\n",
        "# 2. Feature, Label 나누기 \n",
        "X = train.drop(['id', 'y', 'shares'], axis=1)\n",
        "y = train['y']\n",
        "\n",
        "# 3. Train/Validation 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Neural Network 모델 만들기 (BatchNormalization 추가, Dropout 줄이고 learning_rate 조정)\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(1, activation='sigmoid')  # 이진 분류 문제니까 sigmoid 사용\n",
        "])\n",
        "\n",
        "# 5. 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0004),  # learning rate 살짝 줄임\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 6. EarlyStopping 콜백 설정\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 7. 모델 학습\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# 8. 테스트 데이터 준비 (id는 제거)\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "\n",
        "# 9. 예측 (확률 예측)\n",
        "prob_predictions = model.predict(X_test)\n",
        "\n",
        "# 10. 확률을 0.48 기준으로 0 또는 1로 변환\n",
        "threshold = 0.48\n",
        "y_predictions = (prob_predictions >= threshold).astype(int)\n",
        "\n",
        "# 11. 결과 저장 (id + y_predict + y_prob)\n",
        "submission = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'y_predict': y_predictions.flatten(),\n",
        "    'y_prob': prob_predictions.flatten()\n",
        "})\n",
        "\n",
        "submission.to_csv('prediction.csv', index=False)\n",
        "\n",
        "print(\"Done! 결과는 prediction.csv에 저장됐습니다.\")\n",
        "\n",
        "# 12. Validation 데이터로 F1 Score, AUC, Classification Report 계산\n",
        "val_prob_predictions = model.predict(X_val)\n",
        "val_predictions = (val_prob_predictions >= threshold).astype(int)\n",
        "\n",
        "f1 = f1_score(y_val, val_predictions)\n",
        "auc = roc_auc_score(y_val, val_prob_predictions)\n",
        "\n",
        "print(f\"Validation F1 Score: {f1:.4f}\")\n",
        "print(f\"Validation AUC Score: {auc:.4f}\")\n",
        "\n",
        "# 추가: precision, recall, f1-score, support 모두 출력\n",
        "report = classification_report(y_val, val_predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
